training:
  mini_batch_size: 64
  num_actions: 6
  num_episodes: 2000
  num_epochs: 200
  learning_rate: 0.001
  loss: huber
  train_steps: 4
  warmup_episode: 0
  weight_updates: 400


optimizer:
  name: adam
  lr_min: 0.0001
  lr_decay: 5000

rl:
  gamma: 0.99
  max_steps_per_episode: 100
  target_update_episodes: 100
  max_queue_length: 5000 

epsilon:
  max_epsilon: 0.9
  min_epsilon: 0.05
  decay_epsilon: 0.1